{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Immaczx/SemanticSegmentation/blob/master/Notebooks/ResUnetSegmentationZeaMaysSeeds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHINBlmO2MyY",
        "outputId": "7f9a8784-c51c-4c5e-ebe7-ab2240391310"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gcpds-image-segmentation (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install -U git+https://github.com/UN-GCPDS/python-gcpds.image_segmentation.git --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "URAxy4INg7-F",
        "outputId": "a3bfa842-70b5-4b4f-ffc2-04e83461ebb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'SemanticSegmentation'...\n",
            "remote: Enumerating objects: 184, done.\u001b[K\n",
            "remote: Counting objects: 100% (184/184), done.\u001b[K\n",
            "remote: Compressing objects: 100% (137/137), done.\u001b[K\n",
            "remote: Total 184 (delta 84), reused 144 (delta 44), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (184/184), 42.48 KiB | 6.07 MiB/s, done.\n",
            "Resolving deltas: 100% (84/84), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Immaczx/SemanticSegmentation.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qK_MWgkgkXiS"
      },
      "outputs": [],
      "source": [
        "from SemanticSegmentation import utils\n",
        "import os\n",
        "import math as m\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gcpds.image_segmentation.datasets.segmentation import ZeaMaysSeeds\n",
        "from gcpds.image_segmentation.losses import DiceCoefficient\n",
        "from gcpds.image_segmentation.metrics import Jaccard, Sensitivity, Specificity\n",
        "from gcpds.image_segmentation.metrics import DiceCoefficientMetric\n",
        "from gcpds.image_segmentation.models import unet_baseline, fcn_baseline, segnet_baseline, res_unet_baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DIQF9VPu3Yx5"
      },
      "outputs": [],
      "source": [
        "image_size=256\n",
        "out_channels = 1\n",
        "\n",
        "model = res_unet_baseline(input_shape=(image_size,image_size,3), out_channels=out_channels)\n",
        "model.compile(loss=DiceCoefficient(), optimizer='Adam', metrics=[DiceCoefficientMetric(), Jaccard(), Sensitivity(), Specificity()])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lA12H6cC7-YH",
        "outputId": "41719c10-c4c6-41b8-a70b-49cc07795d6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Number of images for Partition 1: 2016\n",
            " Number of images for Partition 2: 864\n",
            " Number of images for Partition 3: 320\n"
          ]
        }
      ],
      "source": [
        "num = np.random.randint(0, 100)\n",
        "dataset = ZeaMaysSeeds(split=[0.1,0.3], seed = num)\n",
        "train,val,test = dataset()\n",
        "\n",
        "def preprocess(img,mask):\n",
        "    img = tf.image.resize(img,(256,256))\n",
        "    mask = tf.image.resize(mask,(256,256))#Ch 1: Seed, Ch 2: No germinate, Ch 3: germinate\n",
        "    mask = tf.cast(mask>0, tf.float32)\n",
        "    mask = mask[...,2][..., None]\n",
        "    return img,mask\n",
        "\n",
        "train = train.map(lambda x,y,id:preprocess(x,y))\n",
        "train = train.batch(1)\n",
        "val = val.map(lambda x,y,id:preprocess(x,y))\n",
        "val = val.batch(1)\n",
        "test = test.map(lambda x,y,id:preprocess(x,y))\n",
        "test = test.batch(1)\n",
        "\n",
        "train = train.cache()\n",
        "val = val.cache()\n",
        "test = test.cache()\n",
        "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "model_history = model.fit(train,validation_data=val, epochs=100, verbose=0)\n",
        "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "fig = plt.figure(figsize=(16,9))\n",
        "\n",
        "gs = fig.add_gridspec(2, 2)\n",
        "ax1 = fig.add_subplot(gs[0, :])\n",
        "ax2 = fig.add_subplot(gs[1, :-1])\n",
        "ax3 = fig.add_subplot(gs[1:, -1])\n",
        "\n",
        "for i in model_history.history:\n",
        "  ax1.plot(model_history.history[i],label=i)\n",
        "ax1.set_title('Model history')\n",
        "ax1.legend()\n",
        "ax1.grid()\n",
        "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "img_test = tf.zeros((0, 256, 256, 3), dtype=tf.float32)\n",
        "mask_test = tf.zeros((0, 256, 256,1), dtype=tf.float32)\n",
        "\n",
        "for img, mask in test:\n",
        "    img_test = tf.concat([img_test, img], axis=0)\n",
        "    mask_test = tf.concat([mask_test, mask], axis=0)\n",
        "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "mask_pred = model.predict(img_test)\n",
        "mask_pred = np.where(mask_pred > .5, 1, 0)\n",
        "evaluate_history = model.evaluate(img_test, mask_test)\n",
        "bars = ax3.barh([\"loss\",\"Dice\",\"Jaccard\",\"Sensitivity\",\"Specificity\"],np.abs(evaluate_history))\n",
        "ax3.bar_label(bars)\n",
        "ax3.set_title('Evaluate metrics')\n",
        "ax3.grid()\n",
        "\n",
        "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "# Then, convert the predicted and ground truth masks to single-dimensional arrays\n",
        "pred_flat = tf.reshape(mask_pred, [-1])\n",
        "true_flat = tf.reshape(mask_test, [-1])\n",
        "\n",
        "# Plot the confusion matrix\n",
        "utils.plot_confusion_matrix(true_flat, pred_flat, classes=['Background','Seed'], ax = ax2)\n",
        "ax2.set_title('confusion matrix')\n",
        "\n",
        "# Ajustar los espacios entre los subplots\n",
        "fig.subplots_adjust(wspace=0.3, hspace=0.3)\n",
        "\n",
        "# Mostrar la figura\n",
        "plt.show()\n",
        "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
        "del train, val, test, dataset\n",
        "tf.keras.backend.clear_session()\n",
        "#----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rqf-PUPlsXWK"
      },
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}